{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standard import statements for a MAST Mashup API request</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "try: # Python 3.x\n",
    "    from urllib.parse import quote as urlencode\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2.x\n",
    "    from urllib import pathname2url as urlencode\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "try: # Python 3.x\n",
    "    import http.client as httplib \n",
    "except ImportError:  # Python 2.x\n",
    "    import httplib   \n",
    "\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the MAST query module to handle appropriate formatting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mastQuery(request):\n",
    "    \"\"\"Perform a MAST query.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        request (dictionary): The MAST request json object\n",
    "        \n",
    "        Returns head,content where head is the response HTTP headers, and content is the returned data\"\"\"\n",
    "    \n",
    "    server='mast.stsci.edu'\n",
    "\n",
    "    # Grab Python Version \n",
    "    version = \".\".join(map(str, sys.version_info[:3]))\n",
    "\n",
    "    # Create Http Header Variables\n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\",\n",
    "               \"Accept\": \"text/plain\",\n",
    "               \"User-agent\":\"python-requests/\"+version}\n",
    "\n",
    "    # Encoding the request as a json string\n",
    "    requestString = json.dumps(request)\n",
    "    requestString = urlencode(requestString)\n",
    "    \n",
    "    # opening the https connection\n",
    "    conn = httplib.HTTPSConnection(server)\n",
    "\n",
    "    # Making the query\n",
    "    conn.request(\"POST\", \"/api/v0/invoke\", \"request=\"+requestString, headers)\n",
    "\n",
    "    # Getting the response\n",
    "    resp = conn.getresponse()\n",
    "    head = resp.getheaders()\n",
    "    content = resp.read().decode('utf-8')\n",
    "\n",
    "    # Close the https connection\n",
    "    conn.close()\n",
    "\n",
    "    return head,content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Here is where we begin to customize the code to perform our own queries:</h3>\n",
    "<p>The first search below sends a filtered query to count all planned observations, designated by a calibration level of -1.  In the 'data' entry, we can see 'Column1' returns with 22133 planned observation entries.</p>\n",
    "<ul>\n",
    "    <li>\"service\":\"Mast.Caom.Filtered.TestV230\" defines the current test server.</li>\n",
    "    <li>\"paramName\":\"calib_level\" allows us to filter based on calibration level.</li>\n",
    "    <li>\"values\":[\"-1\"] defines a planned observation.</li>\n",
    "    <li>Currently it isn't necessary to filter for JWST since those are the only entries present.</li>\n",
    "</ul>\n",
    "<p>Additional parameters to filter on:</p>\n",
    "<ul>\n",
    "    <li>target_name</li>\n",
    "    <li>s_ra</li>\n",
    "    <li>s_dec</li>\n",
    "    <li>obs_collection</li>\n",
    "    <li>instrument</li>\n",
    "    <li>filters</li>\n",
    "    <li>proposal_id</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': [{'Column1': 21882}],\n",
      "    'fields': [{'name': 'Column1', 'type': 'string'}],\n",
      "    'msg': '',\n",
      "    'paging': {   'page': 1,\n",
      "                  'pageSize': 1,\n",
      "                  'pagesFiltered': 1,\n",
      "                  'rows': 1,\n",
      "                  'rowsFiltered': 1,\n",
      "                  'rowsTotal': 1},\n",
      "    'status': 'COMPLETE'}\n"
     ]
    }
   ],
   "source": [
    "mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230\",\n",
    "                 \"format\":\"json\",\n",
    "                 \"params\":{\n",
    "                     \"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only return a count of the results\n",
    "                     \"filters\":[\n",
    "                         {\"paramName\":\"calib_level\",\n",
    "                          \"values\":[\"-1\"],\n",
    "                         },\n",
    "                         {\"paramName\":\"obs_collection\",\n",
    "                          \"values\":[\"JWST\"]\n",
    "                         }\n",
    "                     ]}}\n",
    "    \n",
    "headers,outString = mastQuery(mashupRequest)\n",
    "countData = json.loads(outString)\n",
    "\n",
    "pp.pprint(countData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Searching by position</h4>\n",
    "<p>First off, in order to send a filtered position search via the API, we'll need to submit the position in question in degrees.  Converting an ICRS position to degrees is made pretty easy by using the astropy.coordinates SkyCoord class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64.03904166666666, -24.07236111111111)\n"
     ]
    }
   ],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Use SkyCoord class to convert to degrees\n",
    "def convert_to_degrees(our_ra, our_dec):\n",
    "    coords = SkyCoord(our_ra, our_dec, frame='icrs')\n",
    "    ra_deg = coords.ra.deg\n",
    "    dec_deg = coords.dec.deg\n",
    "    in_degrees = (ra_deg, dec_deg)\n",
    "    return in_degrees\n",
    "\n",
    "# Select our coordinates\n",
    "RA = '04h16m09.370s'\n",
    "DEC = '-24d04m20.50s'\n",
    "SAMPLE_COORDS = convert_to_degrees(RA, DEC)\n",
    "print(SAMPLE_COORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that we have our RA and Dec available in degrees, we can define a radius (also in degrees) and submit a filtered position query.  In this first case, we keep the \"columns\":\"COUNT_BIG(*)\" to simply return a count of the results, in case we hit a large number of entries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "def filtered_position_count(coordinates, radius=0.2):    # radius also in degrees\n",
    "    ra_deg = coordinates[0]\n",
    "    dec_deg = coordinates[1]\n",
    "    mashupRequest = {\n",
    "            \"service\":\"Mast.Caom.Filtered.TestV230.Position\",\n",
    "            \"format\":\"json\",\n",
    "            \"params\":{\n",
    "                \"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only return a count of the results\n",
    "                \"filters\":[\n",
    "                    {\"paramName\":\"calib_level\",\n",
    "                     \"values\":[\"-1\"]\n",
    "                    },\n",
    "                    {\"paramName\":\"obs_collection\",\n",
    "                     \"values\":[\"JWST\"]\n",
    "                    }],\n",
    "                \"position\":\"{0}, {1}, {2}\".format(ra_deg, dec_deg, radius)\n",
    "            }}\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    data = countData['data']\n",
    "    count = data[0]['Column1']\n",
    "    return count\n",
    "\n",
    "TEST_COUNT = filtered_position_count(SAMPLE_COORDS)\n",
    "print(TEST_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the above result we see we get 164 results, so we can go ahead and submit the full request.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 planned observations at 64.0342, -24.0667138888889 (00h00m01.162s +00d00m20.33s away)\n",
      "Found 103 planned observations at 64.0390416666667, -24.0723611111111 (target match)\n",
      "Found 36 planned observations at 64.0416666666667, -24.0661111111111 (00h00m00.63s +00d00m22.5s away)\n"
     ]
    }
   ],
   "source": [
    "def filtered_position_query(coordinates, radius=0.2):\n",
    "    ra_deg = coordinates[0]\n",
    "    dec_deg = coordinates[1]\n",
    "    mashupRequest = {\n",
    "            \"service\":\"Mast.Caom.Filtered.TestV230.Position\",\n",
    "            \"format\":\"json\",\n",
    "            \"params\":{\n",
    "                \"columns\":\"*\",    # return all fields\n",
    "                \"filters\":[\n",
    "                    {\"paramName\":\"calib_level\",\n",
    "                     \"values\":[\"-1\"]\n",
    "                    },\n",
    "                    {\"paramName\":\"obs_collection\",\n",
    "                     \"values\":[\"JWST\"]\n",
    "                    }],\n",
    "                \"position\":\"{0}, {1}, {2}\".format(ra_deg, dec_deg, radius)\n",
    "            }}\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    return countData\n",
    "\n",
    "def find_conflicting_targets(our_target, countData):\n",
    "    data = countData['data']\n",
    "    ra_target = our_target[0]\n",
    "    dec_target = our_target[1]\n",
    "    targets = {}\n",
    "    \n",
    "    # Create a dictionary of all unique coordinate pairs along with a count of how many times they are found\n",
    "    for current in data:\n",
    "        obsid = current['obsid']\n",
    "        current_ra = current['s_ra']\n",
    "        current_dec = current['s_dec']\n",
    "        current_coords = (current_ra, current_dec)\n",
    "        if current_coords in targets.keys():\n",
    "            targets[current_coords] += 1\n",
    "        else:\n",
    "            targets[current_coords] = 1\n",
    "\n",
    "    # For each unique coordinate pair, calculate the distance from the target and display our results\n",
    "    for x in sorted(targets.keys()):\n",
    "        num_obs = targets[x]\n",
    "        unique_ra = x[0]\n",
    "        unique_dec = x[1]\n",
    "        result = \"Found {0} planned observations at {1}, {2}\".format(num_obs, unique_ra, unique_dec)\n",
    "        distance_ra = abs(unique_ra - ra_target)\n",
    "        distance_dec = abs(unique_dec - dec_target)\n",
    "        distance = SkyCoord(distance_ra, distance_dec, frame=\"icrs\", unit='deg')\n",
    "        if distance_ra < 0.001 and distance_dec < 0.001:    # Coordinates may be rounded differently\n",
    "            result += \" (target match)\"\n",
    "        else:\n",
    "            result += \" ({0} away)\".format(distance.to_string('hmsdms'))\n",
    "        print(result)\n",
    "        \n",
    "    return targets\n",
    "\n",
    "TEST_QUERY = filtered_position_query(SAMPLE_COORDS)\n",
    "TEST_TARGETS = find_conflicting_targets(SAMPLE_COORDS, TEST_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save results to a file</h4>\n",
    "<p>This gives us a basic idea of how many observations are currently planned in the vicinity, but we'd now like to examine these observations in more detail.  We can do this by saving the results of our query into a CSV table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/pforshay/Documents/1801_plannedobs/planned_obs.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv_file(countData, filename):\n",
    "    \n",
    "    # Column names are stored in the 'fields' dictionary\n",
    "    fields = countData['fields']\n",
    "    header = []\n",
    "    for entry in fields:\n",
    "        header.append(entry['name'])\n",
    "\n",
    "    # Use the DictWriter class to write the data dictionary to a .csv file\n",
    "    directory = os.getcwd()\n",
    "    filename = directory + \"/\" + filename\n",
    "    data = countData['data']\n",
    "    with open(filename, 'w') as output:\n",
    "        writer = csv.DictWriter(output, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        for obs in data:\n",
    "            writer.writerow(obs)\n",
    "        output.close()\n",
    "        \n",
    "    print(\"Saved {0}\".format(filename))\n",
    "    return filename\n",
    "    \n",
    "# Choose a filename for the resulting CSV table\n",
    "SAVE_AS = 'planned_obs.csv'\n",
    "SAVED = write_to_csv_file(TEST_QUERY, SAVE_AS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Process multiple targets</h4>\n",
    "<p>We now have a CSV table with all available parameters of all observations found within a 0.2 degree radius of a set of sample coordinates.  The API allows us to now take this one step further and bring all these modules together and check multiple sets of coordinates back-to-back.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...checking ('04h16m09.370s', '-24d04m20.50s')...\n",
      "Found 13 planned observations at 64.0342, -24.0667138888889 (00h00m01.162s +00d00m20.33s away)\n",
      "Found 103 planned observations at 64.0390416666667, -24.0723611111111 (target match)\n",
      "Found 36 planned observations at 64.0416666666667, -24.0661111111111 (00h00m00.63s +00d00m22.5s away)\n",
      "Saved /Users/pforshay/Documents/1801_plannedobs/results_04h16m09.370s_-24d04m20.50s.csv\n",
      "...checking ('05h42m15s', '+48d22m43s')...\n",
      "No conflicts found for ('05h42m15s', '+48d22m43s')\n",
      "...checking ('13h36m59.849s', '-29d51m42.97s')...\n",
      "Found 2 planned observations at 204.195833333333, -29.9213888888889 (00h00m12.849s +00d03m34.03s away)\n",
      "Found 273 planned observations at 204.2493725, -29.8619361111111 (target match)\n",
      "Found 2 planned observations at 204.253829166667, -29.8657611111111 (00h00m01.07s +00d00m13.77s away)\n",
      "Found 2 planned observations at 204.3125, -29.8138888888889 (00h00m15.151s +00d02m52.97s away)\n",
      "Saved /Users/pforshay/Documents/1801_plannedobs/results_13h36m59.849s_-29d51m42.97s.csv\n",
      "...checking ('20h20m20.20s', '+20d20m20.20s')...\n",
      "No conflicts found for ('20h20m20.20s', '+20d20m20.20s')\n"
     ]
    }
   ],
   "source": [
    "def check_multiple_targets(coordinates_list):\n",
    "    \n",
    "    # Iterate through our list of coordinate tuples\n",
    "    for target in coordinates_list:\n",
    "        print(\"...checking {0}...\".format(target))\n",
    "        \n",
    "        # Convert each pair of coordinates to degrees\n",
    "        in_degrees = convert_to_degrees(target[0], target[1])\n",
    "        \n",
    "        # Submit an initial count query\n",
    "        count = filtered_position_count(in_degrees)\n",
    "        \n",
    "        # If the count is within a valid range, submit the full query\n",
    "        if count > 0 and count < 50000:\n",
    "            query_results = filtered_position_query(in_degrees)\n",
    "            conflicts = find_conflicting_targets(in_degrees, query_results)\n",
    "            \n",
    "            # Generate a filename and write the information to a CSV table\n",
    "            filename = \"results_{0}_{1}.csv\".format(target[0], target[1])\n",
    "            filename = write_to_csv_file(query_results, filename)\n",
    "            \n",
    "        # Skip if too many results are found\n",
    "        elif count > 50000:\n",
    "            print(\"More than 50,000 results found!  Please narrow your query.\")\n",
    "            \n",
    "        # Skip if no results are found\n",
    "        elif count == 0:\n",
    "            print(\"No conflicts found for {0}\".format(target))\n",
    "\n",
    "\n",
    "OUR_COORDINATES_LIST = [('04h16m09.370s', '-24d04m20.50s'),\n",
    "                        ('05h42m15s', '+48d22m43s'),\n",
    "                        ('13h36m59.849s', '-29d51m42.97s'),\n",
    "                        ('20h20m20.20s', '+20d20m20.20s')\n",
    "                       ]\n",
    "check_multiple_targets(OUR_COORDINATES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
