{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standard import statements for a MAST Mashup API request</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "try: # Python 3.x\n",
    "    from urllib.parse import quote as urlencode\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2.x\n",
    "    from urllib import pathname2url as urlencode\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "try: # Python 3.x\n",
    "    import http.client as httplib \n",
    "except ImportError:  # Python 2.x\n",
    "    import httplib   \n",
    "\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the MAST query module to handle appropriate formatting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mastQuery(request):\n",
    "    \"\"\"Perform a MAST query.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        request (dictionary): The MAST request json object\n",
    "        \n",
    "        Returns head,content where head is the response HTTP headers, and content is the returned data\"\"\"\n",
    "    \n",
    "    server='mast.stsci.edu'\n",
    "\n",
    "    # Grab Python Version \n",
    "    version = \".\".join(map(str, sys.version_info[:3]))\n",
    "\n",
    "    # Create Http Header Variables\n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\",\n",
    "               \"Accept\": \"text/plain\",\n",
    "               \"User-agent\":\"python-requests/\"+version}\n",
    "\n",
    "    # Encoding the request as a json string\n",
    "    requestString = json.dumps(request)\n",
    "    requestString = urlencode(requestString)\n",
    "    \n",
    "    # opening the https connection\n",
    "    conn = httplib.HTTPSConnection(server)\n",
    "\n",
    "    # Making the query\n",
    "    conn.request(\"POST\", \"/api/v0/invoke\", \"request=\"+requestString, headers)\n",
    "\n",
    "    # Getting the response\n",
    "    resp = conn.getresponse()\n",
    "    head = resp.getheaders()\n",
    "    content = resp.read().decode('utf-8')\n",
    "\n",
    "    # Close the https connection\n",
    "    conn.close()\n",
    "\n",
    "    return head,content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Here is where we begin to customize the code to perform our own queries:</h3>\n",
    "<p>The first search below sends a filtered query to count all planned observations, designated by a calibration level of -1.  In the 'data' entry, we can see 'Column1' returns with 22133 planned observation entries.</p>\n",
    "<ul>\n",
    "    <li>\"service\":\"Mast.Caom.Filtered.TestV230\" defines the current test server.</li>\n",
    "    <li>\"paramName\":\"calib_level\" allows us to filter based on calibration level.</li>\n",
    "    <li>\"values\":[\"-1\"] defines a planned observation.</li>\n",
    "    <li>Currently it isn't necessary to filter for JWST since those are the only entries present.</li>\n",
    "</ul>\n",
    "<p>Additional parameters to filter on:</p>\n",
    "<ul>\n",
    "    <li>target_name</li>\n",
    "    <li>s_ra</li>\n",
    "    <li>s_dec</li>\n",
    "    <li>obs_collection</li>\n",
    "    <li>instrument</li>\n",
    "    <li>filters</li>\n",
    "    <li>proposal_id</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': [{'Column1': 11918}],\n",
      "    'fields': [{'name': 'Column1', 'type': 'string'}],\n",
      "    'msg': '',\n",
      "    'paging': {   'page': 1,\n",
      "                  'pageSize': 1,\n",
      "                  'pagesFiltered': 1,\n",
      "                  'rows': 1,\n",
      "                  'rowsFiltered': 1,\n",
      "                  'rowsTotal': 1},\n",
      "    'status': 'COMPLETE'}\n"
     ]
    }
   ],
   "source": [
    "mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230\",\n",
    "                 \"format\":\"json\",\n",
    "                 \"params\":{\n",
    "                     \"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "                     \"filters\":[\n",
    "                         {\"paramName\":\"calib_level\",\n",
    "                          \"values\":[\"-1\"],\n",
    "                         },\n",
    "                         {\"paramName\":\"obs_collection\",\n",
    "                          \"values\":[\"JWST\"]\n",
    "                         },\n",
    "                         {\"paramName\":\"proposal_type\",\n",
    "                          \"values\":[\"ERS\", \"GTO\"]                             \n",
    "                         }\n",
    "                     ]}}\n",
    "    \n",
    "headers,outString = mastQuery(mashupRequest)\n",
    "countData = json.loads(outString)\n",
    "\n",
    "pp.pprint(countData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Searching by position</h3>\n",
    "<p>First off, in order to send a filtered position search via the API, we'll need to submit the position in question in degrees.  Converting an ICRS position to degrees is made pretty easy by using the <a href=\"http://docs.astropy.org/en/stable/coordinates/\" target=\"_blank\">astropy.coordinates SkyCoord class</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64.03904166666666, -24.07236111111111)\n"
     ]
    }
   ],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Use SkyCoord class to convert to degrees\n",
    "def convert_to_degrees(our_ra, our_dec):\n",
    "    coords = SkyCoord(our_ra, our_dec)\n",
    "    ra_deg = coords.ra.deg\n",
    "    dec_deg = coords.dec.deg\n",
    "    in_degrees = (ra_deg, dec_deg)\n",
    "    return in_degrees\n",
    "\n",
    "# Select our coordinates\n",
    "RA = '04h16m09.370s'\n",
    "DEC = '-24d04m20.50s'\n",
    "SAMPLE_COORDS = convert_to_degrees(RA, DEC)\n",
    "print(SAMPLE_COORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that we have our RA and Dec available in degrees, we can define a radius (also in degrees) and submit a filtered position query.  In this first case, we keep the \"columns\":\"COUNT_BIG(*)\" to simply return a count of the results, in case we hit a large number of entries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "def filtered_position_count(coordinates, radius=0.2):    # radius also in degrees\n",
    "    ra_deg = coordinates[0]\n",
    "    dec_deg = coordinates[1]\n",
    "    mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230.Position\",\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "                               \"filters\":[{\"paramName\":\"calib_level\",\n",
    "                                           \"values\":[\"-1\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"obs_collection\",\n",
    "                                           \"values\":[\"JWST\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"proposal_type\",\n",
    "                                           \"values\":[\"ERS\", \"GTO\"]\n",
    "                                          }],\n",
    "                               \"position\":\"{0}, {1}, {2}\".format(ra_deg, dec_deg, radius)\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    data = countData['data']\n",
    "    count = data[0]['Column1']\n",
    "    return count\n",
    "\n",
    "TEST_COUNT = filtered_position_count(SAMPLE_COORDS)\n",
    "print(TEST_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the above result we see we get 164 results, so we can go ahead and submit the full request.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 planned observations at 64.0342, -24.0667138888889 (00h00m01.162s +00d00m20.33s away)\n",
      "Found 103 planned observations at 64.0390416666667, -24.0723611111111 (target match)\n",
      "Found 36 planned observations at 64.0416666666667, -24.0661111111111 (00h00m00.63s +00d00m22.5s away)\n"
     ]
    }
   ],
   "source": [
    "def filtered_position_query(coordinates, radius=0.2):\n",
    "    ra_deg = coordinates[0]\n",
    "    dec_deg = coordinates[1]\n",
    "    mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230.Position\",\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":\"*\",    # return all fields\n",
    "                               \"filters\":[{\"paramName\":\"calib_level\",\n",
    "                                           \"values\":[\"-1\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"obs_collection\",\n",
    "                                           \"values\":[\"JWST\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"proposal_type\",\n",
    "                                           \"values\":[\"ERS\", \"GTO\"]\n",
    "                                          }],\n",
    "                               \"position\":\"{0}, {1}, {2}\".format(ra_deg, dec_deg, radius)\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    return countData\n",
    "\n",
    "def find_conflicting_targets(our_target, countData):\n",
    "    data = countData['data']\n",
    "    ra_target = our_target[0]\n",
    "    dec_target = our_target[1]\n",
    "    targets = {}\n",
    "    \n",
    "    # Create a dictionary of all unique coordinate pairs along with a count of how many times they\n",
    "    # are found\n",
    "    for current in data:\n",
    "        obsid = current['obsid']\n",
    "        current_ra = current['s_ra']\n",
    "        current_dec = current['s_dec']\n",
    "        current_coords = (current_ra, current_dec)\n",
    "        if current_coords in targets.keys():\n",
    "            targets[current_coords] += 1\n",
    "        else:\n",
    "            targets[current_coords] = 1\n",
    "\n",
    "    # For each unique coordinate pair, calculate the distance from the target and display our \n",
    "    # results\n",
    "    for x in sorted(targets.keys()):\n",
    "        num_obs = targets[x]\n",
    "        unique_ra = x[0]\n",
    "        unique_dec = x[1]\n",
    "        result = \"Found {0} planned observations at {1}, {2}\".format(num_obs, \n",
    "                                                                     unique_ra, \n",
    "                                                                     unique_dec)\n",
    "        distance_ra = abs(unique_ra - ra_target)\n",
    "        distance_dec = abs(unique_dec - dec_target)\n",
    "        distance = SkyCoord(distance_ra, distance_dec, frame=\"icrs\", unit='deg')\n",
    "        if distance_ra < 0.001 and distance_dec < 0.001:    # Account for rounding differences\n",
    "            result += \" (target match)\"\n",
    "        else:\n",
    "            result += \" ({0} away)\".format(distance.to_string('hmsdms'))\n",
    "        print(result)\n",
    "        \n",
    "    return targets\n",
    "\n",
    "TEST_QUERY = filtered_position_query(SAMPLE_COORDS)\n",
    "TEST_TARGETS = find_conflicting_targets(SAMPLE_COORDS, TEST_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving results to a file</h3>\n",
    "<p>This gives us a basic idea of how many observations are currently planned in the vicinity, but we'd now like to examine these observations in more detail.  We can do this by saving the results of our query into a CSV table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/pforshay/Documents/1801_plannedobs/planned_obs.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv_file(countData, filename):\n",
    "    \n",
    "    # Column names are stored in the 'fields' dictionary\n",
    "    fields = countData['fields']\n",
    "    header = []\n",
    "    for entry in fields:\n",
    "        header.append(entry['name'])\n",
    "\n",
    "    # Use the DictWriter class to write the data dictionary to a .csv file\n",
    "    directory = os.getcwd()\n",
    "    filename = directory + \"/\" + filename\n",
    "    data = countData['data']\n",
    "    with open(filename, 'w') as output:\n",
    "        writer = csv.DictWriter(output, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        for obs in data:\n",
    "            writer.writerow(obs)\n",
    "        output.close()\n",
    "        \n",
    "    print(\"Saved {0}\".format(filename))\n",
    "    return filename\n",
    "    \n",
    "# Choose a filename for the resulting CSV table\n",
    "SAVE_AS = 'planned_obs.csv'\n",
    "SAVED = write_to_csv_file(TEST_QUERY, SAVE_AS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Process multiple targets</h3>\n",
    "<p>We now have a CSV table with all available parameters of all observations found within a 0.2 degree radius of a set of sample coordinates.  The API allows us to now take this one step further and bring all these modules together and check multiple sets of coordinates back-to-back.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...checking ('04h16m09.370s', '-24d04m20.50s')...\n",
      "Found 13 planned observations at 64.0342, -24.0667138888889 (00h00m01.162s +00d00m20.33s away)\n",
      "Found 103 planned observations at 64.0390416666667, -24.0723611111111 (target match)\n",
      "Found 36 planned observations at 64.0416666666667, -24.0661111111111 (00h00m00.63s +00d00m22.5s away)\n",
      "Saved /Users/pforshay/Documents/1801_plannedobs/results_04h16m09.370s_-24d04m20.50s.csv\n",
      "...checking ('05h42m15s', '+48d22m43s')...\n",
      "No conflicts found for ('05h42m15s', '+48d22m43s')\n",
      "...checking ('13h36m59.849s', '-29d51m42.97s')...\n",
      "No conflicts found for ('13h36m59.849s', '-29d51m42.97s')\n",
      "...checking ('20h20m20.20s', '+20d20m20.20s')...\n",
      "No conflicts found for ('20h20m20.20s', '+20d20m20.20s')\n"
     ]
    }
   ],
   "source": [
    "def check_multiple_targets(coordinates_list, coordinates_format):\n",
    "    \n",
    "    # Iterate through our list of coordinate tuples\n",
    "    for target in coordinates_list:\n",
    "        print(\"...checking {0}...\".format(target))\n",
    "        \n",
    "        # Convert each pair of coordinates to degrees if necessary\n",
    "        if coordinates_format.lower() == \"deg\":\n",
    "            in_degrees = target\n",
    "        else:\n",
    "            in_degrees = convert_to_degrees(target[0], target[1])\n",
    "        \n",
    "        # Submit an initial count query\n",
    "        count = filtered_position_count(in_degrees)\n",
    "        \n",
    "        # If the count is within a valid range, submit the full query\n",
    "        if count > 0 and count < 50000:\n",
    "            query_results = filtered_position_query(in_degrees)\n",
    "            conflicts = find_conflicting_targets(in_degrees, query_results)\n",
    "            \n",
    "            # Generate a filename and write the information to a CSV table\n",
    "            filename = \"results_{0}_{1}.csv\".format(target[0], target[1])\n",
    "            filename = write_to_csv_file(query_results, filename)\n",
    "            \n",
    "        # Skip if too many results are found\n",
    "        elif count > 50000:\n",
    "            print(\"More than 50,000 results found!  Please narrow your query.\")\n",
    "            \n",
    "        # Skip if no results are found\n",
    "        elif count == 0:\n",
    "            print(\"No conflicts found for {0}\".format(target))\n",
    "\n",
    "\n",
    "OUR_COORDINATES_LIST = [('04h16m09.370s', '-24d04m20.50s'),\n",
    "                        ('05h42m15s', '+48d22m43s'),\n",
    "                        ('13h36m59.849s', '-29d51m42.97s'),\n",
    "                        ('20h20m20.20s', '+20d20m20.20s')\n",
    "                       ]\n",
    "check_multiple_targets(OUR_COORDINATES_LIST, \"icrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting coordinates from target names</h3>\n",
    "<p>Using the API also gives us access to the name-resolver service, which allows us to input a list of target names instead of coordinates.  The returned coordinates are already in degrees, so we can also skip the convert_to_degrees module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MESSIER 092 at (259.28029, 43.13652)\n",
      "Found RMC 136 at (84.67665, -69.100933)\n",
      "Found M  27 at (299.901579, 22.721042)\n",
      "Fake Test Galaxy not found\n",
      "...checking (259.28029, 43.13652)...\n",
      "Found 8 planned observations at 259.210094166667, 43.1458638888889 (00h00m16.847s +00d00m33.638s away)\n",
      "Saved /Users/pforshay/Documents/1801_plannedobs/results_259.28029_43.13652.csv\n",
      "...checking (84.67665, -69.100933)...\n"
     ]
    }
   ],
   "source": [
    "def resolve_target_names(target_list):\n",
    "    \n",
    "    # Set up an empty list for coordinate results and iterate through the list of target names\n",
    "    coordinates_list = []\n",
    "    for target_name in target_list:\n",
    "        \n",
    "        # Make a resolver request with the current target name\n",
    "        resolverRequest = {'service':'Mast.Name.Lookup',\n",
    "                           'params':{'input':target_name,\n",
    "                                     'format':'json'}\n",
    "                          }\n",
    "        headers, resolvedObjectString = mastQuery(resolverRequest)\n",
    "        resolvedObject = json.loads(resolvedObjectString)\n",
    "        \n",
    "        # If the target name was not found, we will run into IndexErrors when we try to set these \n",
    "        # variables\n",
    "        try:\n",
    "            target_ra = resolvedObject['resolvedCoordinate'][0]['ra']\n",
    "            target_dec = resolvedObject['resolvedCoordinate'][0]['decl']\n",
    "            canonical_name = resolvedObject['resolvedCoordinate'][0]['canonicalName']\n",
    "        except IndexError:\n",
    "            print(\"{0} not found\".format(target_name))\n",
    "            continue\n",
    "            \n",
    "        # Add the coordinates as a tuple to the list\n",
    "        target_coords = (target_ra, target_dec)\n",
    "        coordinates_list.append(target_coords)\n",
    "        print(\"Found {0} at {1}\".format(canonical_name, target_coords))\n",
    "        \n",
    "    return coordinates_list\n",
    "\n",
    "OUR_TARGETS_LIST = ['M92',\n",
    "                    '30 Doradus',\n",
    "                    'Dumbbell Nebula',\n",
    "                    'Fake Test Galaxy'\n",
    "                   ]\n",
    "NEW_COORDINATES_LIST = resolve_target_names(OUR_TARGETS_LIST)\n",
    "check_multiple_targets(NEW_COORDINATES_LIST, \"deg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Searching for moving targets (keyword searches on target_name)</h3>\n",
    "<p>Moving targets are a bit trickier since we do not have a single set of coordinates to search against.  Instead, we'll look for matching entries in the target_name field and we'll use the freeText paramter with wildcards to find any close matches.  Again, we'll begin with an initial \"COUNT_BIG(*)\" query to get a results count first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_keyword_count(keyword):\n",
    "    mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230\",\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "                               \"filters\":[{\"paramName\":\"calib_level\",\n",
    "                                           \"values\":[\"-1\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"obs_collection\",\n",
    "                                           \"values\":[\"JWST\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"proposal_type\",\n",
    "                                           \"values\":[\"ERS\", \"GTO\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"target_name\",\n",
    "                                           \"values\":[],\n",
    "                                           \"freeText\":\"%\"+keyword+\"%\"\n",
    "                                          }]\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    data = countData['data']\n",
    "    count = data[0]['Column1']\n",
    "    return count\n",
    "\n",
    "JUPITER_COUNT = filtered_keyword_count(\"Jupiter\")\n",
    "print(JUPITER_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We find 82 target names containing \"Jupiter\", so we'll go ahead and submit the full query.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_keyword_query(keyword):\n",
    "    mashupRequest = {\"service\":\"Mast.Caom.Filtered.TestV230\",\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":\"*\",\n",
    "                               \"filters\":[{\"paramName\":\"calib_level\",\n",
    "                                           \"values\":[\"-1\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"obs_collection\",\n",
    "                                           \"values\":[\"JWST\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"proposal_type\",\n",
    "                                           \"values\":[\"ERS\", \"GTO\"]\n",
    "                                          },\n",
    "                                          {\"paramName\":\"target_name\",\n",
    "                                           \"values\":[],\n",
    "                                           \"freeText\":\"%\"+keyword+\"%\"\n",
    "                                          }]\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    countData = json.loads(outString)\n",
    "    return countData\n",
    "\n",
    "# Create a list of the unique target names that were returned by the filtered_keyword_query\n",
    "def keyword_matches(countData):\n",
    "    data = countData['data']\n",
    "    targets = []\n",
    "    for obs in data:\n",
    "        current_target = obs['target_name']\n",
    "        targets.append(current_target)\n",
    "    unique_targets = list(set(targets))\n",
    "    print(\"Matched the keyword to: {0}\".format(unique_targets))\n",
    "    return unique_targets\n",
    "    \n",
    "JUPITER_QUERY = filtered_keyword_query(\"Jupiter\")\n",
    "JUPITER_MATCHES = keyword_matches(JUPITER_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copying our multiple targets module from above, with a few tweaks we can now run back-to-back queries on a list of moving target names.  We can also incorporate the write_to_csv_file module to automatically save all our results for further inspection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_keywords(keywords_list):\n",
    "    \n",
    "    # Iterate through our list of target_name keywords\n",
    "    for target in keywords_list:\n",
    "        print(\"...checking {0}...\".format(target))\n",
    "        \n",
    "        # Submit an initial count query\n",
    "        count = filtered_keyword_count(target)\n",
    "        \n",
    "        # If the count is within a valid range, submit the full query\n",
    "        if count > 0 and count < 50000:\n",
    "            query_results = filtered_keyword_query(target)\n",
    "            conflicts = keyword_matches(query_results)\n",
    "            \n",
    "            # Generate a filename and write the information to a CSV table\n",
    "            filename = \"results_{0}.csv\".format(target)\n",
    "            filename = write_to_csv_file(query_results, filename)\n",
    "            \n",
    "        # Skip if too many results are found\n",
    "        elif count > 50000:\n",
    "            print(\"More than 50,000 results found!  Please narrow your query.\")\n",
    "            \n",
    "        # Skip if no results are found\n",
    "        elif count == 0:\n",
    "            print(\"No conflicts found for {0}\".format(target))\n",
    "            \n",
    "OUR_MOVING_TARGETS = [\"Jupiter\",\n",
    "                      \"Ceres\",\n",
    "                      \"Titan\",\n",
    "                      \"Sun\"\n",
    "                     ]\n",
    "check_multiple_keywords(OUR_MOVING_TARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
